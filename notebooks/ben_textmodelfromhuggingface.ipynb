{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-keras\n",
      "  Downloading tf_keras-2.18.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tensorflow<2.19,>=2.18 in /Users/user/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tf-keras) (2.18.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/user/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/user/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.5.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /Users/user/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/user/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.37.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/user/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/user/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/user/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /Users/user/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (63.2.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /Users/user/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/user/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/user/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /Users/user/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.4.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/user/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.67.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /Users/user/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (5.28.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/user/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /Users/user/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/user/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (4.12.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/user/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: packaging in /Users/user/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (24.1)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /Users/user/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.12.1)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Users/user/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (24.3.25)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/user/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/user/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<2.19,>=2.18->tf-keras) (0.44.0)\n",
      "Requirement already satisfied: namex in /Users/user/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.0.8)\n",
      "Requirement already satisfied: optree in /Users/user/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.13.0)\n",
      "Requirement already satisfied: rich in /Users/user/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (13.9.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/user/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (2024.8.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/user/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/user/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/user/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (2.2.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/user/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.7)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/user/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.1.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/user/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/user/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.0.2)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/user/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/user/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/user/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.1.2)\n",
      "Installing collected packages: tf-keras\n",
      "Successfully installed tf-keras-2.18.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.46.2-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting torch\n",
      "  Downloading torch-2.5.1-cp310-none-macosx_11_0_arm64.whl (63.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers<0.21,>=0.20\n",
      "  Downloading tokenizers-0.20.3-cp310-cp310-macosx_11_0_arm64.whl (2.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /Users/user/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: requests in /Users/user/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Collecting tqdm>=4.27\n",
      "  Downloading tqdm-4.67.0-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0.2-cp310-cp310-macosx_11_0_arm64.whl (171 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.8/171.8 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting safetensors>=0.4.1\n",
      "  Downloading safetensors-0.4.5-cp310-cp310-macosx_11_0_arm64.whl (381 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.23.2\n",
      "  Downloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.5/447.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/user/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from transformers) (2.0.2)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2024.11.6-cp310-cp310-macosx_11_0_arm64.whl (284 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.6/284.6 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sympy==1.13.1\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.8.0 in /Users/user/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Collecting fsspec\n",
      "  Downloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.6/179.6 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting jinja2\n",
      "  Downloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting networkx\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting mpmath<1.4,>=1.1.0\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /Users/user/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/user/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/user/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/user/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/user/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n",
      "Installing collected packages: mpmath, tqdm, sympy, safetensors, regex, pyyaml, networkx, jinja2, fsspec, filelock, torch, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed filelock-3.16.1 fsspec-2024.10.0 huggingface-hub-0.26.2 jinja2-3.1.4 mpmath-1.3.0 networkx-3.4.2 pyyaml-6.0.2 regex-2024.11.6 safetensors-0.4.5 sympy-1.13.1 tokenizers-0.20.3 torch-2.5.1 tqdm-4.67.0 transformers-4.46.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Installer les dépendances\n",
    "!pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer les bibliothèques nécessaires\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "import torch\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le modèle et le tokenizer\n",
    "MODEL = \"jy46604790/Fake-News-Bert-Detect\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aucun GPU disponible\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Vérifier si un GPU est disponible\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU disponible : {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"Aucun GPU disponible\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le pipeline avec le modèle et le tokenizer\n",
    "clf = pipeline(\"text-classification\", model=MODEL, tokenizer=MODEL, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de prétraitement\n",
    "def preprocess_text(text):\n",
    "    # Convertir en minuscules\n",
    "    text = text.lower()\n",
    "    # Remplacer les URL par un token générique\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"[URL]\", text, flags=re.MULTILINE)\n",
    "    # Supprimer les caractères spéciaux\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n",
    "    # Supprimer les espaces multiples\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple de texte\n",
    "texts = [\"C’est un pari réussi pour Vladimir Poutine qui après avoir perdu de justesse contre Joe Biden en 2020 est de retour à la Maison-Blanche. Le président russe s’est félicité d’avoir remporté ce scrutin et a déjà annoncé son intention de terminer le travail en Ukraine, puis d’aider la Chine à régler ce petit souci avec Taiwan et solutionner ce petit différent avec les Pays-Baltes, puis enfin l’Europe.\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_0', 'score': 0.9789045453071594}]\n"
     ]
    }
   ],
   "source": [
    "# Effectuer les prédictions\n",
    "for text in texts:\n",
    "    result = clf(text)  # Le résultat est un dictionnaire contenant le label et le score\n",
    "    print(result)\n",
    "    #print(f\"Text: {text}\")\n",
    "    #print(f\"Prediction: {result[0]['label']} (Confidence: {result[0]['score']:.5f})\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cest un pari russi pour vladimir poutine qui aprs avoir perdu de justesse contre joe biden en 2020 est de retour la maisonblanche le prsident russe sest flicit davoir remport ce scrutin et a dj annonc son intention de terminer le travail en ukraine puis daider la chine rgler ce petit souci avec taiwan et solutionner ce petit diffrent avec les paysbaltes puis enfin leurope']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Appliquer le prétraitement\n",
    "preprocessed_texts = [preprocess_text(text) for text in texts]\n",
    "preprocessed_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0, 35678,   542,  2242,   118,   910,  4781,   118,  9650,   748,\n",
       "         15356, 32850,   181, 35543, 15087, 28200,    29,  6402, 13878,   228,\n",
       "          6588,   263,    95, 19616,  8541,   241, 13509,   242,  2311,   225,\n",
       "          1177,  2760,  3304,   263,  5494,  2126,   897,  9131,  4060,  3662,\n",
       "         13706,  2084,  3349,    29,  8009,   910,   687,  1090,   579,   990,\n",
       "           856,  5895,   405,   385,  1469, 13878,  6398,  3427,  8635, 18470,\n",
       "          4400,    10, 29831,  9915,   261,   438,   979,  6589,   263, 19022,\n",
       "           254,  2084,  8419,   705,  3760,  1177,  1717,   330, 23535, 18829,\n",
       "           354,  2955,  5326,   897,  1855,   833, 49015,  1371,  8635,  4716,\n",
       "           405, 22272,  2520,    10, 25369,   326,  1439,  6531,  4400,  2472,\n",
       "          1396,  8635,  4716,   405, 25871,  9854,    10, 25369,  7427,  7634,\n",
       "           428,  3967,   293, 18829,   354,  1177, 13597,  2084,  7367,  2379,\n",
       "             2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1]])}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenizer les données\n",
    "inputs = tokenizer(preprocessed_texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9883, 0.0117]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Effectuer des prédictions\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    #predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "\n",
    "predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: C’est un pari réussi pour Vladimir Poutine qui après avoir perdu de justesse contre Joe Biden en 2020 est de retour à la Maison-Blanche. Le président russe s’est félicité d’avoir remporté ce scrutin et a déjà annoncé son intention de terminer le travail en Ukraine, puis d’aider la Chine à régler ce petit souci avec Taiwan et solutionner ce petit différent avec les Pays-Baltes, puis enfin l’Europe.\n",
      "Preprocessed Text: cest un pari russi pour vladimir poutine qui aprs avoir perdu de justesse contre joe biden en 2020 est de retour la maisonblanche le prsident russe sest flicit davoir remport ce scrutin et a dj annonc son intention de terminer le travail en ukraine puis daider la chine rgler ce petit souci avec taiwan et solutionner ce petit diffrent avec les paysbaltes puis enfin leurope\n",
      "Prediction: Real (Confidence: 0.99)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Interpréter les résultats\n",
    "labels = [\"Real\", \"Fake\"]  # Selon la documentation du modèle\n",
    "for i, text in enumerate(texts):\n",
    "    pred_label = labels[torch.argmax(predictions[i]).item()]\n",
    "    confidence = predictions[i][torch.argmax(predictions[i])].item()\n",
    "    print(f\"Original Text: {text}\")\n",
    "    print(f\"Preprocessed Text: {preprocessed_texts[i]}\")\n",
    "    print(f\"Prediction: {pred_label} (Confidence: {confidence:.2f})\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
